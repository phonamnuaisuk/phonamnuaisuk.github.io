{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets\n",
    "\n",
    "## Preprocessing and Features representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Make numpy values easier to read.\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iris Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X = iris.data[:, (2, 3)]  # petal length, petal width\n",
    "y = (iris.target == 0).astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f182179c040>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(X[y==0, 0], X[y==0, 1], \"bs\", label=\"Not Iris-Setosa\")\n",
    "plt.plot(X[y==1, 0], X[y==1, 1], \"yo\", label=\"Iris-Setosa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_model = tf.keras.Sequential([\n",
    "  layers.Dense(2),\n",
    "  layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_model.compile(loss = tf.losses.MeanSquaredError(),optimizer = tf.optimizers.Adam(), metrics=['mae','mape'])\n",
    "#iris_model.compile(loss = tf.losses.MeanSquaredError(),optimizer = tf.optimizers.Adam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5/5 [==============================] - 0s 846us/step - loss: 0.1463 - accuracy: 0.6667\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 782us/step - loss: 0.1434 - accuracy: 0.6667\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 706us/step - loss: 0.1406 - accuracy: 0.6667\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 819us/step - loss: 0.1380 - accuracy: 0.6667\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 805us/step - loss: 0.1349 - accuracy: 0.6667\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 848us/step - loss: 0.1324 - accuracy: 0.6667\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1299 - accuracy: 0.6667\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 920us/step - loss: 0.1274 - accuracy: 0.6667\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 711us/step - loss: 0.1250 - accuracy: 0.6667\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1226 - accuracy: 0.6667\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 728us/step - loss: 0.1207 - accuracy: 0.6667\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 694us/step - loss: 0.1187 - accuracy: 0.6667\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 772us/step - loss: 0.1170 - accuracy: 0.6667\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 660us/step - loss: 0.1153 - accuracy: 0.6667\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 617us/step - loss: 0.1139 - accuracy: 0.6667\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 614us/step - loss: 0.1124 - accuracy: 0.6733\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 775us/step - loss: 0.1110 - accuracy: 0.6733\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 716us/step - loss: 0.1098 - accuracy: 0.7000\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 730us/step - loss: 0.1088 - accuracy: 0.7000\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 703us/step - loss: 0.1076 - accuracy: 0.7000\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 582us/step - loss: 0.1066 - accuracy: 0.7000\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 613us/step - loss: 0.1055 - accuracy: 0.7000\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.1045 - accuracy: 0.7133\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 766us/step - loss: 0.1036 - accuracy: 0.8533\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 652us/step - loss: 0.1026 - accuracy: 0.8933\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 635us/step - loss: 0.1016 - accuracy: 0.8933\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 609us/step - loss: 0.1007 - accuracy: 0.8933\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 693us/step - loss: 0.0998 - accuracy: 0.8933\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 611us/step - loss: 0.0988 - accuracy: 0.8933\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 656us/step - loss: 0.0979 - accuracy: 0.8933\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 650us/step - loss: 0.0970 - accuracy: 0.8933\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 631us/step - loss: 0.0961 - accuracy: 0.8933\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 681us/step - loss: 0.0952 - accuracy: 0.8933\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 635us/step - loss: 0.0943 - accuracy: 0.8933\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 778us/step - loss: 0.0934 - accuracy: 0.9400\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 674us/step - loss: 0.0925 - accuracy: 0.9400\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 654us/step - loss: 0.0916 - accuracy: 0.9400\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 745us/step - loss: 0.0907 - accuracy: 0.9400\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 769us/step - loss: 0.0898 - accuracy: 0.9400\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 764us/step - loss: 0.0890 - accuracy: 0.9400\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 786us/step - loss: 0.0880 - accuracy: 0.9400\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 873us/step - loss: 0.0872 - accuracy: 0.9400\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 694us/step - loss: 0.0863 - accuracy: 0.9400\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 763us/step - loss: 0.0855 - accuracy: 0.9400\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 906us/step - loss: 0.0846 - accuracy: 0.9400\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 791us/step - loss: 0.0837 - accuracy: 0.9400\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 775us/step - loss: 0.0829 - accuracy: 0.9400\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 941us/step - loss: 0.0821 - accuracy: 0.9400\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 0s 846us/step - loss: 0.0812 - accuracy: 0.9400\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s 789us/step - loss: 0.0804 - accuracy: 0.9400\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s 948us/step - loss: 0.0796 - accuracy: 0.9400\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 773us/step - loss: 0.0788 - accuracy: 0.9733\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 761us/step - loss: 0.0780 - accuracy: 0.9867\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 894us/step - loss: 0.0772 - accuracy: 0.9867\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 0s 723us/step - loss: 0.0765 - accuracy: 0.9867\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s 769us/step - loss: 0.0756 - accuracy: 0.9867\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0748 - accuracy: 0.9867\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s 721us/step - loss: 0.0741 - accuracy: 0.9867\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 0s 766us/step - loss: 0.0733 - accuracy: 0.9867\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 0s 910us/step - loss: 0.0725 - accuracy: 0.9867\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0612 - accuracy: 1.00 - 0s 808us/step - loss: 0.0717 - accuracy: 0.9867\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s 783us/step - loss: 0.0711 - accuracy: 0.9867\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 0s 812us/step - loss: 0.0702 - accuracy: 0.9867\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 0s 680us/step - loss: 0.0695 - accuracy: 0.9867\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 0s 687us/step - loss: 0.0688 - accuracy: 0.9867\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 0s 950us/step - loss: 0.0680 - accuracy: 0.9867\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 0s 856us/step - loss: 0.0673 - accuracy: 0.9867\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 0s 802us/step - loss: 0.0666 - accuracy: 0.9867\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 0s 803us/step - loss: 0.0659 - accuracy: 0.9867\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 0s 653us/step - loss: 0.0651 - accuracy: 0.9867\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 0s 659us/step - loss: 0.0644 - accuracy: 0.9867\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 0s 722us/step - loss: 0.0637 - accuracy: 0.9867\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 0s 741us/step - loss: 0.0630 - accuracy: 0.9867\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 0s 645us/step - loss: 0.0624 - accuracy: 0.9867\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 0s 695us/step - loss: 0.0617 - accuracy: 0.9867\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.0610 - accuracy: 0.9867\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 0s 635us/step - loss: 0.0604 - accuracy: 0.9933\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 0s 746us/step - loss: 0.0597 - accuracy: 0.9933\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 0s 734us/step - loss: 0.0590 - accuracy: 0.9933\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 0s 794us/step - loss: 0.0584 - accuracy: 0.9933\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 0s 699us/step - loss: 0.0577 - accuracy: 0.9933\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 672us/step - loss: 0.0571 - accuracy: 0.9933\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0565 - accuracy: 0.9933\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 0s 658us/step - loss: 0.0559 - accuracy: 0.9933\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 0s 696us/step - loss: 0.0553 - accuracy: 0.9933\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 0s 816us/step - loss: 0.0546 - accuracy: 0.9933\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 0s 720us/step - loss: 0.0540 - accuracy: 0.9933\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 0s 761us/step - loss: 0.0535 - accuracy: 0.9933\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 0s 724us/step - loss: 0.0529 - accuracy: 0.9933\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 0s 850us/step - loss: 0.0523 - accuracy: 0.9933\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 0s 609us/step - loss: 0.0517 - accuracy: 0.9933\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 0s 634us/step - loss: 0.0511 - accuracy: 0.9933\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 0s 877us/step - loss: 0.0506 - accuracy: 0.9933\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 0s 747us/step - loss: 0.0501 - accuracy: 0.9933\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 0s 781us/step - loss: 0.0495 - accuracy: 0.9933\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 0s 816us/step - loss: 0.0489 - accuracy: 0.9933\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 0s 774us/step - loss: 0.0484 - accuracy: 0.9933\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 0s 652us/step - loss: 0.0478 - accuracy: 0.9933\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 0s 720us/step - loss: 0.0474 - accuracy: 0.9933\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 0s 825us/step - loss: 0.0468 - accuracy: 0.9933\n"
     ]
    }
   ],
   "source": [
    "history = iris_model.fit(X, y, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.702],\n",
       "       [0.702],\n",
       "       [0.701],\n",
       "       [0.702],\n",
       "       [0.702],\n",
       "       [0.595],\n",
       "       [0.649],\n",
       "       [0.702],\n",
       "       [0.702],\n",
       "       [0.75 ],\n",
       "       [0.702],\n",
       "       [0.703],\n",
       "       [0.75 ],\n",
       "       [0.747],\n",
       "       [0.7  ],\n",
       "       [0.593],\n",
       "       [0.591],\n",
       "       [0.649],\n",
       "       [0.652],\n",
       "       [0.65 ],\n",
       "       [0.704],\n",
       "       [0.593],\n",
       "       [0.698],\n",
       "       [0.536],\n",
       "       [0.706],\n",
       "       [0.703],\n",
       "       [0.594],\n",
       "       [0.702],\n",
       "       [0.702],\n",
       "       [0.703],\n",
       "       [0.703],\n",
       "       [0.593],\n",
       "       [0.75 ],\n",
       "       [0.702],\n",
       "       [0.702],\n",
       "       [0.7  ],\n",
       "       [0.701],\n",
       "       [0.75 ],\n",
       "       [0.701],\n",
       "       [0.702],\n",
       "       [0.648],\n",
       "       [0.648],\n",
       "       [0.701],\n",
       "       [0.474],\n",
       "       [0.597],\n",
       "       [0.649],\n",
       "       [0.703],\n",
       "       [0.702],\n",
       "       [0.702],\n",
       "       [0.702],\n",
       "       [0.131],\n",
       "       [0.105],\n",
       "       [0.107],\n",
       "       [0.157],\n",
       "       [0.106],\n",
       "       [0.16 ],\n",
       "       [0.085],\n",
       "       [0.271],\n",
       "       [0.161],\n",
       "       [0.127],\n",
       "       [0.273],\n",
       "       [0.104],\n",
       "       [0.278],\n",
       "       [0.131],\n",
       "       [0.155],\n",
       "       [0.13 ],\n",
       "       [0.105],\n",
       "       [0.279],\n",
       "       [0.105],\n",
       "       [0.231],\n",
       "       [0.055],\n",
       "       [0.157],\n",
       "       [0.107],\n",
       "       [0.197],\n",
       "       [0.159],\n",
       "       [0.13 ],\n",
       "       [0.132],\n",
       "       [0.069],\n",
       "       [0.105],\n",
       "       [0.273],\n",
       "       [0.23 ],\n",
       "       [0.275],\n",
       "       [0.191],\n",
       "       [0.087],\n",
       "       [0.105],\n",
       "       [0.085],\n",
       "       [0.106],\n",
       "       [0.159],\n",
       "       [0.158],\n",
       "       [0.157],\n",
       "       [0.195],\n",
       "       [0.131],\n",
       "       [0.192],\n",
       "       [0.271],\n",
       "       [0.158],\n",
       "       [0.193],\n",
       "       [0.158],\n",
       "       [0.159],\n",
       "       [0.224],\n",
       "       [0.158],\n",
       "       [0.011],\n",
       "       [0.044],\n",
       "       [0.029],\n",
       "       [0.057],\n",
       "       [0.023],\n",
       "       [0.03 ],\n",
       "       [0.068],\n",
       "       [0.058],\n",
       "       [0.057],\n",
       "       [0.011],\n",
       "       [0.035],\n",
       "       [0.044],\n",
       "       [0.028],\n",
       "       [0.035],\n",
       "       [0.014],\n",
       "       [0.017],\n",
       "       [0.056],\n",
       "       [0.023],\n",
       "       [0.019],\n",
       "       [0.107],\n",
       "       [0.018],\n",
       "       [0.035],\n",
       "       [0.037],\n",
       "       [0.055],\n",
       "       [0.028],\n",
       "       [0.058],\n",
       "       [0.055],\n",
       "       [0.055],\n",
       "       [0.028],\n",
       "       [0.089],\n",
       "       [0.046],\n",
       "       [0.037],\n",
       "       [0.022],\n",
       "       [0.108],\n",
       "       [0.136],\n",
       "       [0.018],\n",
       "       [0.014],\n",
       "       [0.056],\n",
       "       [0.055],\n",
       "       [0.028],\n",
       "       [0.014],\n",
       "       [0.017],\n",
       "       [0.044],\n",
       "       [0.018],\n",
       "       [0.011],\n",
       "       [0.017],\n",
       "       [0.044],\n",
       "       [0.035],\n",
       "       [0.017],\n",
       "       [0.055]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dense/kernel:0' shape=(2, 2) dtype=float32, numpy=\n",
       " array([[ 0.603,  0.282],\n",
       "        [ 0.054, -1.413]], dtype=float32)>,\n",
       " <tf.Variable 'dense/bias:0' shape=(2,) dtype=float32, numpy=array([-0.352,  0.397], dtype=float32)>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_model.layers[0].weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For any small CSV dataset the simplest way to train a TensorFlow model on it is to load it into memory as a pandas Dataframe or a NumPy array. \n",
    "\n",
    "## Abalone dataset\n",
    "\n",
    "Numeric data, Regression to predict Abalone age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abalone_train = pd.read_csv(\n",
    "    \"https://storage.googleapis.com/download.tensorflow.org/data/abalone_train.csv\",\n",
    "    names=[\"Length\", \"Diameter\", \"Height\", \"Whole weight\", \"Shucked weight\",\n",
    "           \"Viscera weight\", \"Shell weight\", \"Age\"])\n",
    "\n",
    "abalone_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abalone_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abalone_features = abalone_train.copy()\n",
    "abalone_labels = abalone_features.pop('Age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abalone_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abalone_model = tf.keras.Sequential([\n",
    "  layers.Dense(64),\n",
    "  layers.Dense(1)\n",
    "])\n",
    "\n",
    "abalone_model.compile(loss = tf.losses.MeanSquaredError(),optimizer = tf.optimizers.Adam(), metrics=['mae','mape'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = abalone_model.fit(abalone_features, abalone_labels, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Titanic dataset\n",
    "\n",
    "Mixed data types, Perform classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = pd.read_csv(\"https://storage.googleapis.com/tf-datasets/titanic/train.csv\")\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_features = titanic.copy()\n",
    "titanic_labels = titanic_features.pop('survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, column in titanic_features.items():\n",
    "    dtype = column.dtype\n",
    "    print(dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {}\n",
    "\n",
    "for name, column in titanic_features.items():\n",
    "    dtype = column.dtype\n",
    "    if dtype == object:\n",
    "        dtype = tf.string\n",
    "    else:\n",
    "        dtype = tf.float32\n",
    "\n",
    "    inputs[name] = tf.keras.Input(shape=(1,), name=name, dtype=dtype)\n",
    "\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_inputs.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_inputs = {name:input for name,input in inputs.items()\n",
    "                  if input.dtype==tf.float32}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_inputs = {name:input for name,input in inputs.items()\n",
    "                  if input.dtype==tf.float32}\n",
    "\n",
    "x = layers.Concatenate()(list(numeric_inputs.values()))\n",
    "norm = preprocessing.Normalization()\n",
    "norm.adapt(np.array(titanic[numeric_inputs.keys()]))\n",
    "all_numeric_inputs = norm(x)\n",
    "\n",
    "all_numeric_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_inputs = [all_numeric_inputs]\n",
    "for name, input in inputs.items():\n",
    "    if input.dtype == tf.float32:\n",
    "        continue\n",
    "\n",
    "    lookup = preprocessing.StringLookup(vocabulary=np.unique(titanic_features[name]))\n",
    "    one_hot = preprocessing.CategoryEncoding(max_tokens=lookup.vocab_size())\n",
    "\n",
    "    x = lookup(input)\n",
    "    x = one_hot(x)\n",
    "    preprocessed_inputs.append(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_inputs_cat = layers.Concatenate()(preprocessed_inputs)\n",
    "\n",
    "titanic_preprocessing = tf.keras.Model(inputs, preprocessed_inputs_cat)\n",
    "\n",
    "tf.keras.utils.plot_model(model = titanic_preprocessing , rankdir=\"LR\", dpi=72, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_features_dict = {name: np.array(value) \n",
    "                         for name, value in titanic_features.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_dict = {name:values[:1] for name, values in titanic_features_dict.items()}\n",
    "titanic_preprocessing(features_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def titanic_model(preprocessing_head, inputs):\n",
    "    body = tf.keras.Sequential([\n",
    "        layers.Dense(64),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "\n",
    "    preprocessed_inputs = preprocessing_head(inputs)\n",
    "    result = body(preprocessed_inputs)\n",
    "    model = tf.keras.Model(inputs, result)\n",
    "\n",
    "    model.compile(loss=tf.losses.BinaryCrossentropy(from_logits=True),optimizer=tf.optimizers.Adam(),metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "titanic_model = titanic_model(titanic_preprocessing, inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = titanic_model.fit(x=titanic_features_dict, y=titanic_labels, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
